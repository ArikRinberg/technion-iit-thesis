\section{Proofs}
\label{fc-sec:proofs}

In Section~\ref{fc-sec:analysis:definitions} we introduce some formalisms.
In Section~\ref{fc-subsec:Generic-algorithm-proof} we prove that
the unoptimized algorithm is strongly linearizable with respect to
the relaxed specification $SeqSketch^r$ with $r=Nb$. Finally,
in Section~\ref{fc-subsec:Optimised-algorithm-proof} we show that
the the optimized algorithm is strongly linearizable with respect to
the relaxed specification $SeqSketch^r$ with $r=2Nb$.

\subsection{Definitions}
\label{fc-sec:analysis:definitions}
Note that the only methods invoked by $ParSketch$ on $globalS$ are snapshot and merge, and since merge is
only invoked by $t_0$, the only concurrency is between a snapshot and another operation (snapshot or merge).
Recall that we required such executions of a composable sketch to be strongly linearizable. By slight abuse
of terminology, we refer to these operations as atomic steps, for example, we refer to the linearization
point of $globalS$.merge simply as ``$globalS$.merge step''.

Likewise, as $localS_i$ is only accessed sequentially by a
single thread, either $t_i$ or $t_0$ (using $prop_i$ to synchronize),
we refer to the method calls shouldAdd and update as atomic steps.

Because we prove only safety properties, we restrict out attention to finite executions.
For analysis purposes we use auxiliary counters:
\begin{itemize}
    \item An array $sig\_ctr[N]$, that counts the number of times each thread $t_i$ signals to the propagator (line~\ref{fc-l:signal}).
    \item An array $merge\_ctr[N]$ counting the number of times $t_0$ executes a merge with thread $t_i$'s local sketch (line~\ref{fc-l:merge}).
\end{itemize}

Recall that in Section~\ref{fc-sec:background}, we said that a sketch's state \emph{summarizes} a
stream or a sequential history if it is the state of a sketch that has processed
the stream or history. We now overload the term ``summarizes'' to apply also to threads.
\begin{definition}[Thread summary]
    Consider a time $t$ in an execution $\sigma$ of Algorithm~\ref{fc-alg:generic-concurrent}. If at time $t$ either $prop_i \neq 0$
    or $sig\_ctr[i]>merge\_ctr[i]$, then we say that update thread $t_i$ \emph{summarizes} the history
    summarized by $localS_i$ at time $t$. Otherwise, thread $t_i$ summarizes the empty history at time $t$.
    The propagator thread $t_0$ summarizes the same history as $globalS$ at any time during an execution $\sigma$.
\label{fc-def:thread-summary}
\end{definition}
Note that if the first condition ($prop_i \neq 0$ or $sig\_ctr[i]>merge\_ctr[i]$) is not satisfied,
this means that the propagator thread might be in the process of clearing $localS_i$ in line~\ref{fc-l:emptyAux}.


As we want to analyze each thread's steps in an execution, we first define the projection from
execution $\sigma$ onto a thread $t_i$.
\begin{definition}[Projection]
    Given a finite execution $\sigma$ and a thread $t_i$, $\sigma\Bigr|_{t_i}$ is the subsequence of
    $\sigma$ consisting of steps taken by $t_i$.
\end{definition}

We want to prove that each thread's summary corresponds to the sequence of updates
processed by that thread since the last propagation, taking
into account only those that alter local state variables. These are updates for which \emph{shouldAdd} returns
true.
\begin{definition}[Unpropogated updates]
    Given a finite execution $\sigma$, we denote by suff$_i(\sigma)$ the suffix of $\sigma \Bigr|_{t_i}$ starting 
    at the last $globalS$.merge($localS_i$) event, or the beginning of $\sigma$ if no such event exists. 
    The unpropogated suffix up\_suff$_i(\sigma)$ of update thread $i$ is 
    the subsequence of $\mathcal{H} ($suff$_i(\sigma))$ consisting of $update(a)$ executions in suff$_i(\sigma)$ for which
    shouldAdd$(hint_i, arg)$ returns true in line \ref{fc-l:shouldAdd}.
    \label{fc-def:unpropogated-suffix}
\end{definition}

We define the relation between a sequential history $H$ and a stream $A$.
\begin{definition}
    Given a finite sequential history $H$, ${\mathcal{S}}(H)$ is the stream $a_1,\dots,a_n$ such that $a_k$
    is the argument of the $k$th update in $H$.
\end{definition}

Finally, we define the notion of \emph{happens before} in a sequential history $H$.
\begin{definition}
    Given a finite sequential history $H$ and two method invocations $M_1,M_2$ in $H$, we denote $M_1 \prec_H M_2$
    if $M_1$ precedes $M_2$ in $H$.
\end{definition}

\subsection{Unoptimized algorithm proof} 
\label{fc-subsec:Generic-algorithm-proof}

Our strong linearizability proof uses two mappings, $f$ and $l$, from 
executions to sequential histories defined as follows.
For an execution $\sigma$ of $ParSketch$, we define a mapping $f$ 
by ordering operations according to \emph{visibility points} defined as follows: 
\begin{itemize}
\item
For a query, the visibility point is the snapshot operation it executes.
\item 
For an update$_i$($a$) where shouldAdd($prop_i$, $a$) returns false at time $t$, its visibility point is $t$.
\item
Otherwise, for an update$_i$($a$), let $t$ be the first time after its invocation in $\sigma$
when thread $i$ changes $prop_i$ to 0 (line~\ref{fc-l:signal}).
Its visibility point is the (linearization point of the) first merge that occurs with $localS_i$ after time t.
If there is no such time, then update$_i$($a$) does not have a visibility point, i.e., is not included in $f(\sigma)$
\end{itemize}
Note that in the latter case,
the visibility point may occur after the update returns, and so $f$ does not 
necessarily preserve real-time order. 
 
We also define a mapping $l$ by ordering operations according to
\emph{linearization points} defined as follows:
\begin{itemize}
    \item
    An updates' linearization point is its invocation
    \item
    A query's linearization point is its visibility point.
\end{itemize}
By definition, $l(\sigma)$ is prefix-preserving.

We show that for every execution $\sigma$ of $ParSketch$,
(1) $f(\sigma) \in SeqSketch$, and 
(2) $f(\sigma)$ is an $r$-relaxation of $l(\sigma)$ for $r=N b$.  
Together, this implies that $l(\sigma) \in SeqSketch^r$, as needed.

We first show that $Prop_i \neq 0$ if $t_i$'s program counter is not on lines \ref{fc-l:signal} or \ref{fc-l:wait}.
\begin{invariant}
    At any time during a finite execution $\sigma$ of $ParSketch$ for every $i=1,\dots,N$, if $t_i$'s program
    counter isn't on lines \ref{fc-l:signal} or \ref{fc-l:wait}, then $prop_i \neq 0$.
    \label{fc-inv:prop-neq-0}
\end{invariant}
\begin{proof}
    The proof is derived immediately from the algorithm: $prop_i$ is initialized to 1 and gets
    the value of 0 on line \ref{fc-l:signal}, and then waits on line \ref{fc-l:wait} until $prop_i \neq 0$.
    After continuing passed line \ref{fc-l:wait}, $prop_i \neq 0$ again.
\end{proof}

We also observe the following:
\begin{observation}
    Given a finite execution $\sigma$ of $ParSketch$, for every $i=1,\dots,N$, every execution
    of $globalS.merge(localS_i)$ in $\sigma$ (line~\ref{fc-l:merge}) is preceded by an execution of $prop_i \leftarrow 0$
    (line~\ref{fc-l:signal}).
\end{observation}

We observe the following relationship between $t_i$'s program counter and $sig\_ctr[i]$ and \linebreak
$merge\_ctr[i]$:
\begin{observation}
    At all times during a finite execution $\sigma$ of $ParSketch$, for every
    $i=1,\dots,N$, $merge\_ctr[i] \leq sig\_ctr[i] \leq merge\_ctr[i] + 1$.
    Moreover, if $t_i$'s program counter isn't on lines \ref{fc-l:signal} or \ref{fc-l:wait}, then $sig\_ctr[i]=merge\_ctr[i]$.
    \label{fc-obs:counter_relationship}
\end{observation}

We show that at every point in an execution, update thread $t_i$ summarizes up\_suff$_i(\sigma)$. 
In essence, this means that we have not ``forgotten" any updates.
\begin{invariant}
    At all times during a finite execution $\sigma$ of $ParSketch$, for every $i=1,\dots,N$, $t_i$ summarizes up\_suff$_i(\sigma)$.
    \label{fc-inv:update-thread-summary}
\end{invariant}
\begin{proof}
    The proof is by induction on the length of $\sigma$. The base is immediate.
    Next we consider a step in $\sigma$ that can alter the invariant. We assume the invariant is correct
    for $\sigma'$, and prove correctness for $\sigma=\sigma',step$. We consider only steps that
    can alter the invariant, meaning the step can 
    either lead to a change in up\_suff$_i(\sigma)$, or a change in the history summarized by $t_i$. This
    means we need to consider only 4 cases:
    \begin{itemize}

        \item A step $localS_i.update(arg)$ (line~\ref{fc-l:update}) by thread $t_i$.

        In this case, up\_suff$_i(\sigma)=$up\_suff$_i(\sigma'),update(arg)$.
        By the inductive hypothesis, before the step $localS_i$ summarizes up\_suff$_i(\sigma')$,
        and so after the update, $localS_i$ summarizes $\text{up\_suff}_i(\sigma'),$ \linebreak $update(arg)=\text{up\_suff}_i(\sigma)$.
        From Invariant~\ref{fc-inv:prop-neq-0} $prop_i \neq 0$, therefore, by Definition \ref{fc-def:thread-summary}, $t_i$ summarizes
        the same history as $localS_i$,
        i.e., up\_suff$_i(\sigma)$, preserving the invariant.

        \item A step $prop_i \leftarrow 0$ (line~\ref{fc-l:signal}) by thread $t_i$.
        
        By the inductive hypothesis, before the step, $t_i$ summarizes the 
        history up\_suff$_i(\sigma')$. Because before the step  $prop_i \ne 0$, $localS_i$ 
				summarizes the same history.
        As no update occurs, up\_suff$_i(\sigma')$=up\_suff$_i(\sigma)$. The step
        doesn't alter $localS_i$, so after the step, $localS_i$ still summarizes
        up\_suff$_i(\sigma)$. On this step the counter $sig\_ctr[i]$ is increased but $merge\_ctr[i]$
        is not, so $sig\_ctr[i]>merge\_ctr[i]$.
        Therefore, by Definition \ref{fc-def:thread-summary}, $t_i$ summarizes the same history as $localS_i$,
        namely up\_suff$_i(\sigma)$, preserving the invariant.

        \item A step $globalS.merge(localS_i)$ (line~\ref{fc-l:merge}) by thread $t_0$.
        
        By Definition~\ref{fc-def:unpropogated-suffix}, after this step up\_suff$_i(\sigma)$ is empty. As
        this step is a $merge$, $merge\_ctr[i]$ is increased by one, so $sig\_ctr[i]=merge\_ctr[i]$ by
        Observation~\ref{fc-obs:counter_relationship}.
        Therefore, by Definition \ref{fc-def:thread-summary}, $t_i$
        summarizes the empty history, preserving the invariant.

        \item A step $prop_i \leftarrow globalS.calcHint()$ (line~\ref{fc-l:calcHint}) by thread $t_0$
        
        Before executing the step, $t_0$ executed line~\ref{fc-l:emptyAux}. Thread $t_i$ is waiting
        for $prop_i \neq 0$ on line~\ref{fc-l:wait}, therefore has not updated $localS_i$.
        Therefore, by Definition~\ref{fc-def:thread-summary}, $localS_i$ summarizes the empty history.
        As a merge with thread $i$ was executed and no updates have been invoked, up\_suff$_i(\sigma)$
        is the empty history.
        The function $calcHint$ cannot return $0$, therefore after that step $prop_i \neq 0$.
        By Definition \ref{fc-def:thread-summary}, $t_i$ summarizes the same history as $localS_i$, i.e., the empty history.
        Therefore, $t_i$ summarizes up\_suff$_i(\sigma)$, preserving the invariant.
    \end{itemize}
\end{proof}

Next, we prove that $t_0$ summarizes $f(\sigma)$.
\begin{invariant}[History of propagator thread]
    Given a finite execution $\sigma$ of $ParSketch$, $t_0$ summarizes $f(\sigma)$.
    \label{fc-inv:G-partial-summary}
\end{invariant}
\begin{proof}
    The proof is by induction on the length of $\sigma$. The base is immediate.
    We assume the invariant is correct for $\sigma'$, and prove correctness for $\sigma=\sigma',step$.
    There are two steps that can alter the invariant.
    \begin{itemize}
        \item A step $globalS.merge(localS_i)$ (line~\ref{fc-l:merge}) by thread $t_0$.
        
        By the inductive hypothesis, before the step, $t_0$ summarizes $f(\sigma')$. And by
        Invariant~\ref{fc-inv:update-thread-summary}, before the update, $t_i$ summarizes
        up\_suff$_i(\sigma')$, and by Invariant~\ref{fc-inv:prop-neq-0} $localS_i$ summarizes the same history.
        Let $A={\mathcal{S}}(f(\sigma))$, and $B={\mathcal{S}}($up\_suff$_i(\sigma')$$)$.
        After the merge $globalS$ summarizes $A||B$. Therefore,
        $t_0$ summarizes $f(\sigma)$ preserving the invariant.

        \item A step shouldAdd($prop_i$, $a$) (line~\ref{fc-l:shouldAdd}) by thread $t_i$, returning false.     
        
        Let $H$ be that last hint returned to $t_i$, and let $\sigma''$ be the prefix of $\sigma$ up to this point.
        By the induction hypothesis, at that point $globalS$ summarized $f(\sigma'')$.
        Let $A=\mathcal{S}$$(f(\sigma''))$, and let $B=\mathcal{S}$$(f(\sigma'))$,
        and let $B_1$ be such that $B=A||B_1$. By the induction hypothesis,
        before the step, $globalS$ summarizes $B=A||B_1$.
        By the assumption of \emph{shouldAdd}, if shouldAdd($H$, $arg$) returns false, then if
        a sketch summarizes $B=A||B_1||B_2$, then it also summarizes $B=A||B_1||a||B_2$. Let
        $B_2=\emptyset$, then $globalS$ summarizes $B=A||B_1||B_2$, therefore also summarizes 
        $A||B_1||a||B_2=A||B_1||a$. Therefore, after the step, $globalS$ summarizes $f(\sigma)$
        preserving the invariant.
    \end{itemize}
\end{proof}

To finish the proof that $f(\sigma) \in SeqSketch$, we prove that a query invoked at the end of $\sigma$
returns a value equal to the value returned by a sequential sketch after processing $A={\mathcal{S}}(f(\sigma))$.
\begin{lemma}[Query Correctness]
    Given a finite execution $\sigma$ of $ParSketch$, let $Q$ be a query that returns
    in $\sigma$, and let $v$ be $Q$'s visibility point. Let $\sigma'$ be the prefix
    of $\sigma$ until point $v$, and let $A={\mathcal{S}}(f(\sigma'))$. $Q$ returns a value
    that is equal to the value returned by a sequential sketch after processing $A$.
    \label{fc-lemma:query-correctness}
\end{lemma}
\begin{proof}
    Let $\sigma$ be an execution of $ParSketch$, and let $Q$ be a query that returns in $\sigma$.
    Let $\sigma'$ and $A$ be as defined in the lemma. By Invariant \ref{fc-inv:G-partial-summary}, 
    $t_0$ summarizes $f(\sigma')$ at point $v$, therefore \emph{globalS} 
    summarizes $f(\sigma')$ at the same point, therefore \emph{globalS} summarizes 
    stream $A$ at point $v$. The visibility point for the query, at point $v$,
    is $globalS.$snapshot$()$. By the requirement from $S$.snapshot(), for all $arg$ 
    $globalS.query(arg)=localCopy.query(arg)$. Because $globalS$ summarizes
    stream $A$, $localCopy.query(arg)$ returns a value equal to the value
    returned by the sequential sketch $globalS$ after processing $A$.
\end{proof}

As we have proven that each query in $f(\sigma)$ returns a value that estimates all
the updates that happen before its invocation, we have proven the following:
\begin{lemma}
    Given a finite execution $\sigma$ of $ParSketch$, $f(\sigma) \in SeqSketch$.
    \label{fc-lemma:f-in-seqsketch}
\end{lemma}

To complete the proof, we prove that $f(\sigma)$ is an $r$-relaxation of $l(\sigma)$, for $r=Nb$.
We begin by proving orders between queries and other method calls.
\begin{lemma}
    Given a finite execution $\sigma$ of $ParSketch$, and given an operation $O$(query or update) in $l(\sigma)$,
    for every $Q$ in $l(\sigma)$ such that $Q \prec_{l(\sigma)} O$,
    then $Q \prec_{f(\sigma)} O$.
    \label{fc-lemma:QueryOrders}
\end{lemma}
\begin{proof}
    If $O$ is a query,
    then proof is immediate from the definitions of $l$ and $f$.
    If $O$ is an update, then, by the definition of $f$, an updates visibility point
    is at the earliest its linearization point.
    As $Q$'s visibility point and linearization point are equal, it follows
    that if  $Q \prec_{l(\sigma)} O$ then $Q \prec_{f(\sigma)} O$.
\end{proof}

We next prove an upper bound on the number of updates in up\_suff$_i(\sigma)$. We denote the
number of updates in history $H$ as $\abs{H}$.
\begin{lemma}
    Given a finite execution $\sigma$ of $ParSketch$, $\abs{\text{up\_suff}_i(\sigma)} \leq b$.
    \label{fc-lemma:update-thread-summary-bound}
\end{lemma}
\begin{proof}
    As $counter_i$ is incremented before an update which is included in $\text{up\_suff}_i(\sigma)$,
    it follows that $\abs{\text{up\_suff}_i(\sigma)} \leq counter_i$. When $counter_i = b$, $t_i$
    signals for a propagation (line~\ref{fc-l:signal}) and then waits until $prop_i \neq 0$ (line~\ref{fc-l:wait}).
    When $t_i$ finishes waiting, then it zeros the counter (line~\ref{fc-l:zeroCounter}) before ingesting
    more updates, therefore, $count_i \leq b$. Therefore, it follows that $\abs{\text{up\_suff}_i(\sigma)} \leq b$.
\end{proof}

As $f(\sigma)$ contains all updates with visibility points, we can now prove the following.
\begin{lemma}
    Given a finite execution $\sigma$ of $ParSketch$, $\abs{f(\sigma)} \geq \abs{l(\sigma)} - N$$b$.
    \label{fc-lemma:f-bound}
\end{lemma}
\begin{proof}
    From Lemma~\ref{fc-lemma:update-thread-summary-bound}, $\abs{\text{up\_suff}_i(\sigma)} \leq b$.
    The only updates without a visibility point are updates that are in up\_suff$_i(\sigma)$ for some $i$.
    Therefore $f(\sigma)$ contains all updates but any update in a history up\_suff$_i(\sigma)$ for some $i$.
    There are $N$ update threads, therefore $\abs{f(\sigma)} = \abs{l(\sigma)} - $$\sum_{i=1}^{N} \abs{\text{up\_suff}_i(\sigma)}$
    so $\abs{f(\sigma)} \geq \abs{l(\sigma)} - N $$b$.
\end{proof}

We will now prove that given an execution $\sigma$ of $ParSketch$, every invocation in $f(\sigma)$
is preceded by all but at most $Nb$ of the invocations in $l(\sigma)$.
\begin{lemma}
    Given a finite execution $\sigma$ of $ParSketch$, $f(\sigma)$ is an Nb-relaxation of $l(\sigma)$.
    \label{fc-lemma:f-relaxing-l}
\end{lemma}
\begin{proof}
    Let $\sigma$ be a finite execution of $ParSketch$, and consider an operation $O$ in $f(\sigma)$
    such that $O$ is also in $l(\sigma)$. Let $Ops = \Set{O'}{(O' \prec_{l(\sigma)} O) \wedge (O' \nprec_{f(\sigma)} O)}$.
    We show that $\abs{Ops} \leq Nb$.
    By Lemma~\ref{fc-lemma:QueryOrders}, for every query $Q$ in $l(\sigma)$ such that $Q \prec_{l(\sigma)} O$,
    then $Q \prec_{f(\sigma)} O$, meaning $Q \notin Ops$.
    Let $\sigma^{pre}$ be a prefix and $\sigma^{post}$ a suffix of $\sigma$ such that
    $l(\sigma)=l(\sigma^{pre}),O,l(\sigma^{post})$. From Lemma~\ref{fc-lemma:f-bound}, $\abs{f(\sigma^{pre})} \geq \abs{l(\sigma^{pre})} - Nb$.
    As $\abs{f(\sigma^{pre})}$ is the number of updates in $f(\sigma^{pre})$, and $\abs{l(\sigma^{pre})}$ is the number of updates
    in $l(\sigma^{pre})$, $f(\sigma^{pre})$ contains all but at most $Nb$ updates in $l(\sigma^{pre})$. As $l(\sigma^{pre})$
    contains all the updates that precede $O$. Meaning $Ops$ is all the updates in $l(\sigma^{pre})$ and not in
    $f(\sigma^{pre})$. Therefore, $\abs{Ops} = \abs{l(\sigma^{pre})} - \abs{f(\sigma^{pre})} \leq Nb$.
    Therefore, by Definition~\ref{fc-def:r-relaxtion}, $f(\sigma)$ is an $Nb$-relaxation of $l(\sigma)$.
\end{proof}

Putting together Lemma~\ref{fc-lemma:f-in-seqsketch} and Lemma~\ref{fc-lemma:f-relaxing-l}, we have shown that
given a finite execution $\sigma$ of $ParSketch$, $f(\sigma) \in SeqSketch$ and $f(\sigma)$ is an $Nb$-relaxation
of $l(\sigma)$. We have proven Lemma~\ref{fc-lemma:genereic-strong}.

\subsection{Optimized algorithm proof}
\label{fc-subsec:Optimised-algorithm-proof}
We denote the optimized version of Algorithm~\ref{fc-alg:generic-concurrent} as \emph{OptParSketch}. 
We prove the correctness of \emph{OptParSketch} by showing that it can simulate  \emph{ParSketch}. 
This proof technique is known as   a \emph{simulation relation}, which, as explained in~\cite{lynch1996distributed}, Chapter 2.5, 
is a correspondence relating the states of \emph{OptParSketch} and \emph{ParSketch} when the algorithms run on the same input stream. 
Establishing a simulation relation proves that $OptParSketch$ is strongly linearizable with regards to 
$SeqSketch^{2Nb}$~\cite{10.1016/j.tcs.2010.09.021,attiya2019putting}.

Consider an arbitrary worker thread $t_i$ for the optimized algorithm,
and simulate this thread using two worker threads $t_i^0,t_i^1$ of the basic algorithm.
%Algorithm~\ref{fc-alg:generic-concurrent}.
To simulate $N$ worker threads, we need $2N$ threads, and they are mapped the same way.

The idea behind the simulation is that there might be a delay between the time when the \emph{hint} is returned to the worker thread and the time when this hint is used for pre-processing, so we can simulate each thread by two threads. For example in Figure~\ref{fc-fig:optimisedSimulation},
each block $A_i$ is a stream such that $b$ updates pass the test of \emph{shouldAdd} (except maybe $A_n$).
The stream processed by $t_i$ is $A=A_1||A_2||\dots||A_n$ and we assume $n$ is even.
Each $A_i$ is evaluated against the \emph{hint} written above it. The thread $t_i^0$ simulates processing
$A_1||A_3||\dots ||A_{n-1}$, and thread $t_i^1$ simulates processing $A_2||A_4||\dots||A_n$.

\begin{figure}[H]
    \centering
    \includegraphics[width=4.2in]{graphics/fast-concurrent/optimisedSimulation.png}
    \caption{Simulation of processing $A=A_1||A_2||\dots||A_n$.}
    \label{fc-fig:optimisedSimulation}
\end{figure}

The simulation uses auxiliary variables oldHint$_i^0$, and oldHint$_i^1$, both initialized to 1.
These variables are updated with the flipping of $cur_i$ (line~\ref{fc-opt:l:swap-local-aux}), such that:
\begin{itemize}
    \item oldHint$_i^0$ is updated to be the current (pre-flip) value of $hint_i$
    \item oldHint$_i^1$ is updated to be the current (pre-flip) value of $oldHint_i^0$
\end{itemize}

%The simulation uses an auxiliary variable $oldHint_i^0$ initialised to 1. This variable is updated
%with the flipping of $cur_i$ (line~\ref{fc-opt:l:swap-local-aux}) with the current value of $hint_i$.

In addition, the simulation uses an auxiliary variable \emph{auxCount$_i$} initialized to 0. This variable is set to
$b$ before the first execution of line~\ref{fc-opt:l:swap-local-aux}, and is never changed after that. 

Finally, the simulation uses two auxiliary variables $PC_i^0$ and $PC_i^1$ to be
program counters for threads $t_i^0$ and $t_i^1$. They are initialized to \emph{Idle}.

We define a mapping $g$ from the state of $OptParSketch$ to the state of $ParSketch$ as follows:
\begin{itemize}
    \item \emph{globalS} in $OptParSketch$ is mapped to \emph{globalS} in $ParSketch$.
    \item localS$_i[j]$ is mapped to $t^j$.localS for $j=0,1$.
    \item counter$_i$ is mapped to $t^{cur_i}$.counter.
    \item auxCount is mapped to $t^{1-cur_i}$.counter.
    \item hint$_i$ is mapped to $t^{cur_i}$.hint and $t^{cur_i}$.prop if $t_i$ is not right before executing line 227,
    otherwise oldHint$_i^0$ is mapped to $t^{cur_i}$.hint and prop$_i$ is mapped to $t^{cur_i}$.prop.
    \item prop$_i$ is mapped to $t^{1-cur_i}$.prop if $t_i$ is not right before executing lines 227-229,
    otherwise oldHint$_i^1$ is mapped to $t^{1-cur_i}$.prop.
    \item oldHint$_i^1$ is mapped to $t^{1-cur_i}$.hint.
\end{itemize}

For example, Figure~\ref{fc-fig:optConcurrentMap} shows a mapping when $cur_i$ equals 0, before executing
line 227. Table~\ref{fc-table:opt-simulation} shows the steps taken by $t_i^0$ and $t_i^1$ when
$cur_i=0$ before line~223.

\begin{figure}[ht]
    \centering
    \includegraphics[width=5in]{graphics/fast-concurrent/optConcurrentMap.png}
    \caption{Reference mapping of $g$ when $cur_i$ equals 0 before executing line 227.}
    \label{fc-fig:optConcurrentMap}
\end{figure}

\begin{table}[H]
    \begin{tabular}{c|c|c}
        \emph{OptParSketch} line & \emph{ParSketch} line & Executing thread\\[5pt]
        \hline
        \ref{fc-opt:l:checkfull} & \ref{fc-l:checkfull} & $t_i^0$\\[5pt]
        \ref{fc-opt:l:wait} & \ref{fc-l:wait}& $t_i^1$\\[5pt]
        \ref{fc-opt:l:swap-local-aux} & - & - \\[5pt]
        \ref{fc-opt:l:updateHint} & \ref{fc-l:updateHint} & $t_i^1$\\[5pt]
        \ref{fc-opt:l:zeroCounter} & \ref{fc-l:zeroCounter} & $t_i^1$\\[5pt]
        \ref{fc-opt:l:signal} & \ref{fc-l:signal} & $t_i^0$ 
    \end{tabular}
    \caption{Example for steps taken by $t_i^0$ and $t_i^1$ for each step taken by $t_i$ when $cur_i=0$ before line~\ref{fc-opt:l:checkfull},
    meaning the ``round'' of $b$ updates was ingested by $t_i^0$. On line~\ref{fc-opt:l:swap-local-aux} neither thread takes a step.}
    \label{fc-table:opt-simulation}
\end{table}

We also define the steps taken in $ParSketch$ when $OptParSketch$ takes a step. If a \emph{query} is invoked,
then both algorithms take the same step. If an \emph{update} in invoked, the  \emph{update} is invoked in
$t_i^{cur_i}$ in $ParSketch$. If the counter gets up to $b$ (meaning we get to line~\ref{fc-opt:l:wait}), then
$t_i^{1-cur_i}$ executes line~\ref{fc-l:wait}. When $OptParSketch$ flips $cur_i$ (line~\ref{fc-opt:l:swap-local-aux}),
then neither of the threads $t_i^0$ or $t_i^1$ take a step. Afterwards, lines \ref{fc-opt:l:updateHint} and \ref{fc-opt:l:zeroCounter} execute the corresponding lines (\ref{fc-l:updateHint} and \ref{fc-l:zeroCounter}) 
on thread $t_i^{cur_i}$, and line \ref{fc-opt:l:signal} executes \ref{fc-l:signal} on thread $t_i^{1-cur_i}$.

\begin{lemma}
    $g$ is a simulation relation from $OptParSketch$ to $ParSketch$.
\end{lemma}
\begin{proof}
The proof is by induction on the steps in an execution, for some thread $i$. In the initial state, the mapping trivially holds.
In a given step, we refer to $t_i^{cur_i}$ as the \emph{active} thread and $t_i^{1-cur_i}$ as the \emph{inactive thread}. 
Query threads trivially map to themselves and do not alter the state. We next consider update and propagator threads. 
First, consider the steps of OptParSketch that execute the corresponding step on the active thread.
These are lines 219--223 and 227--228, which directly correspond to lines 119-123 and 127-128 of ParSketch in the
active thread ($t_i^{cur_i}$), and, except in lines 127 and 129, the effected state variables are mapped to the
same state variables in the active thread. So these steps trivially preserve $g$.
Line 124 in \emph{ParSketch} is executed on the inactive thread when \emph{OptParSketch} executes line 229. As after
this step the inactive thread's prop and prop$_i$ are both $0$, so $g$ is preserved. 
Line 125 is executed on the inactive thread, waiting on the same variable, and modifies no variables, so $g$ is preserved.

Line 226 flips $cur_i$ and neither thread takes a step in \emph{ParSketch}. Here, the mappings of $prop$, $hint$, and $counter$ change. 
On this step oldHint$_i^0$ and oldHint$_i^1$ are updated as defined, and as $t_i$ is right before
executing line 227, oldHint$_i^1$ is equal to the inactive thread's ($t_i^{1-cur_i}$) hint, and, as before the step the (now)
inactive thread's prop was equal to hint$_i$, then after this step it is equal to oldHint$_i^0$.
As before the step the (now) active thread's hint was equal to oldHint$_i^0$, after this step it is equal to oldHint$_i^1$. Finally,
as before the step the (now) active thread's prop was equal to prop$_i$, after this step it remains equal to prop$_i$, so this
step preserve $g$.

In line 227, hint$_i$ gets the value of prop$_i$, and the same happens on the active thread. As before this line the
active thread's prop was equal to prop$_i$, after this step the inactive thread's prop and hint are equal to hint$_i$,
preserving $g$.
As the active thread's counter is equal to $counter_i$, line 228 preserves $g$.
The now inactive thread has filled its local sketch, therefore its counter is $b$, which equals
auxCount.  
Finally, the propagator thread’s steps (lines 210-215) execute on the inactive
thread and it is easy to see that all variables accessed in these steps are mapped to the same variables in the inactive thread. 
\end{proof}

Note that the simulation relation uses no prophecy variables, i.e., does not ``look into the future''.
This establishes strong linearizability~\cite{attiya2019putting}, intuitively, because 
the mapping of all ParSketch’s steps -- including linearization points --  to steps in OptParSketch is prefix-preserving.
Since we use two update threads of ParSketch to simulate one thread in OptParSketch, we have proven the following theorem:

\optgenereicstrong*